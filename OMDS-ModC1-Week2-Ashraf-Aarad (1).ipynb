{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61b8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a5ff99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import kagglehub\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2fc69f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/teamincribo/cyber-security-attacks?dataset_version_number=20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.03M/5.03M [00:00<00:00, 78.1MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the latest version of the dataset\n",
    "path = kagglehub.dataset_download(\"teamincribo/cyber-security-attacks\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Construct the full path to the CSV file (update the file name if necessary)\n",
    "csv_file = os.path.join(path, \"cybersecurity_attacks.csv\")\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2710804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Timestamp               40000 non-null  object \n",
      " 1   Source IP Address       40000 non-null  object \n",
      " 2   Destination IP Address  40000 non-null  object \n",
      " 3   Source Port             40000 non-null  int64  \n",
      " 4   Destination Port        40000 non-null  int64  \n",
      " 5   Protocol                40000 non-null  object \n",
      " 6   Packet Length           40000 non-null  int64  \n",
      " 7   Packet Type             40000 non-null  object \n",
      " 8   Traffic Type            40000 non-null  object \n",
      " 9   Payload Data            40000 non-null  object \n",
      " 10  Malware Indicators      20000 non-null  object \n",
      " 11  Anomaly Scores          40000 non-null  float64\n",
      " 12  Alerts/Warnings         19933 non-null  object \n",
      " 13  Attack Type             40000 non-null  object \n",
      " 14  Attack Signature        40000 non-null  object \n",
      " 15  Action Taken            40000 non-null  object \n",
      " 16  Severity Level          40000 non-null  object \n",
      " 17  User Information        40000 non-null  object \n",
      " 18  Device Information      40000 non-null  object \n",
      " 19  Network Segment         40000 non-null  object \n",
      " 20  Geo-location Data       40000 non-null  object \n",
      " 21  Proxy Information       20149 non-null  object \n",
      " 22  Firewall Logs           20039 non-null  object \n",
      " 23  IDS/IPS Alerts          19950 non-null  object \n",
      " 24  Log Source              40000 non-null  object \n",
      "dtypes: float64(1), int64(3), object(21)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665d755",
   "metadata": {},
   "source": [
    "*Note: Unfortunately due to the nature of the datasets for my project (Network Security), linear models will likely not perform well with these datasets. More complex methods such as neural networks will be required to effectively predict for target values. For the sake of the assignment, I will still run the linear regression models on one of my datasets.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d72dc",
   "metadata": {},
   "source": [
    "**Lasso Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cd15d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56494e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 835.3243\n"
     ]
    }
   ],
   "source": [
    "# Drop columns unlikely to be useful or with too much unstructured text\n",
    "columns_to_drop = [\n",
    "    'Timestamp', 'Payload Data', 'Malware Indicators', 'Alerts/Warnings',\n",
    "    'User Information', 'Device Information', 'Geo-location Data',\n",
    "    'Proxy Information', 'Firewall Logs', 'IDS/IPS Alerts'\n",
    "]\n",
    "\n",
    "df_model = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_model.drop(columns=['Anomaly Scores'])\n",
    "y = df_model['Anomaly Scores']\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessing: one-hot encode categoricals, scale numerics, impute missing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), numeric_cols),\n",
    "    \n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), categorical_cols)\n",
    "])\n",
    "\n",
    "# Full pipeline with Lasso\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('lasso', Lasso(alpha=0.1))  # alpha is regularization strength\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2697b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 28.90\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rmse = np.sqrt(835)\n",
    "print(f'RMSE: {rmse:.2f}')  # Output: ~28.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dabb83c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Score range: 0.0 to 100.0\n",
      "Standard deviation: 28.853598250518676\n"
     ]
    }
   ],
   "source": [
    "print(\"Anomaly Score range:\", y.min(), \"to\", y.max())\n",
    "print(\"Standard deviation:\", y.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c015a54",
   "metadata": {},
   "source": [
    "Based on the RMSE being near equal to the STD, it appears that the model is not much better than just predicting the mean of anomaly scores for every instance. May need to account for categorical features for further effectiveness, but I believe that it still won't help as there linear regression methods may not be best suited for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7282351",
   "metadata": {},
   "source": [
    "**Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c10fcab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5ed46bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 835.97\n",
      "Root Mean Squared Error: 28.91\n"
     ]
    }
   ],
   "source": [
    "# Drop high-cardinality or complex columns\n",
    "columns_to_drop = [\n",
    "    'Timestamp', 'Payload Data', 'Malware Indicators', 'Alerts/Warnings',\n",
    "    'User Information', 'Device Information', 'Geo-location Data',\n",
    "    'Proxy Information', 'Firewall Logs', 'IDS/IPS Alerts'\n",
    "]\n",
    "\n",
    "df_model = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_model.drop(columns=['Anomaly Scores'])\n",
    "y = df_model['Anomaly Scores']\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), numeric_cols),\n",
    "\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), categorical_cols)\n",
    "])\n",
    "\n",
    "# Full pipeline with Ridge Regression\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('ridge', Ridge(alpha=1.0))  # You can tune alpha\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3524b1",
   "metadata": {},
   "source": [
    "Similar results as lasso regression. Could be due to underfitting or that true linear relationships are not present in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25184d5d",
   "metadata": {},
   "source": [
    "**Elastic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "401ae9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06189753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 835.28\n",
      "Root Mean Squared Error: 28.90\n"
     ]
    }
   ],
   "source": [
    "# Drop unstructured or high-cardinality columns\n",
    "columns_to_drop = [\n",
    "    'Timestamp', 'Payload Data', 'Malware Indicators', 'Alerts/Warnings',\n",
    "    'User Information', 'Device Information', 'Geo-location Data',\n",
    "    'Proxy Information', 'Firewall Logs', 'IDS/IPS Alerts'\n",
    "]\n",
    "\n",
    "df_model = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_model.drop(columns=['Anomaly Scores'])\n",
    "y = df_model['Anomaly Scores']\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), numeric_cols),\n",
    "\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), categorical_cols)\n",
    "])\n",
    "\n",
    "# Elastic Net pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('elasticnet', ElasticNet(alpha=1.0, l1_ratio=0.5))  # Mix of L1 and L2\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f11a4",
   "metadata": {},
   "source": [
    "It appears that linear regressions perform poorly on this dataset, which makes sense given the nature of the data being random network traffic. More complex methods such as neural networks are required to make effective predictions for this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
